|Dataset                                                                                                                                                           |Year|Data Availability                                                                                                                                                                           |Data Link                                                                       |Paper Name|Citation                                                                                                                          |Abuse Type|Data Platform                                                                                                                 |Code-mixed?                                                 |# Instances|Language                                                                    |Language Family                           |Label                                                                                                                                                                                                                                                                                                                                   |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------|----|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|----------|----------------------------------------------------------------------------------------------------------------------------------|----------|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------|-----------|----------------------------------------------------------------------------|------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|Paul et al. (2023)                                                                                                                                                |2023|No                                                                                                                                                                                          |                                                                                |COVID-19 and cyberbullying: deep ensemble model to identify cyberbullying from code-switched languages during the pandemic|10                                                                                                                                |cyberbullying|Twitter                                                                                                                       |Yes                                                         |22000      |English, Hindi                                                              |Indo-European -> English, Indo-European -> Hindi|bully and nonbully                                                                                                                                                                                                                                                                                                                      |
|Jiang et al. (2022)                                                                                                                                               |2022|Yes                                                                                                                                                                                         |https://zenodo.org/record/4773875                                               |SWSR: A Chinese dataset and lexicon for online sexism detection|26                                                                                                                                |sexism/misogyny|Weibo                                                                                                                         |No                                                          |8969       |Chinese                                                                     |Sino-Tibetan -> Chinese                   |sexist, non-sexist                                                                                                                                                                                                                                                                                                                      |
|Salaam et al. (2022)                                                                                                                                              |2022|Yes                                                                                                                                                                                         |see description                                                                 |Offensive Content Detection via Synthetic Code-Switched Text|0                                                                                                                                 |offensive |-                                                                                                                             |Yes                                                         |37221      |English, French, German, Spanish                                            |Indo-European -> English, Indo-European -> Italic -> French, Indo-European -> Spanish, Indo-European->Germanic|offensive or not                                                                                                                                                                                                                                                                                                                        |
|KOLD                                                                                                                                                              |2022|Yes                                                                                                                                                                                         |https://github.com/boychaboy/KOLD                                               |KOLD: Korean Offensive Language Dataset|1                                                                                                                                 |offensive |NAVER news, Youtube                                                                                                           |No                                                          |40429      |Korean                                                                      |Koreanic -> Korean                        |Offensive/Not  if Offensive → Untargeted (UNT)/Individual (IND)/Group (GRP)/Others (OTH)               if GRP → Gender & Sexual Orientation/Race, Ethnicity & Nationality/Political         Affiliation/Religion/Miscellaneous                                                                                                          |
|Deng et al. (2022) - COLD                                                                                                                                         |2022|Yes                                                                                                                                                                                         |https://github.com/thu-coai/COLDataset                                          |COLD: A Benchmark for Chinese Offensive Language Detection|13                                                                                                                                |offensive |Weibo, Zhihu                                                                                                                  |No                                                          |37480      |Chinese                                                                     |Sino-Tibetan -> Chinese                   |binary offensive label fine-grained level with four categories: attacking individuals, attacking groups, anti-bias and other non-offensive.                                                                                                                                                                                             |
|Gupta et al. (2022) - MACD                                                                                                                                        |2022|Yes                                                                                                                                                                                         |https://github.com/ShareChatAI/MACD                                             |MACD: MultilingualMultilingual Abusive Comment Detection at Scale for Indic Languages|0                                                                                                                                 |abusive   |ShareChat                                                                                                                     |Yes                                                         |92881      |Hindi, Kannada, Malayalam, Tamil, Telugu                                    |Dravidian -> Kannada, Dravidian -> Malayalam, Dravidian -> Tamil, Dravidian -> Telugu, Indo-European -> Hindi|binary labels (abusive and non-abusive) representing                                                                                                                                                                                                                                                                                    |
|Chakravarthi et al. (2021)                                                                                                                                        |2022|Yes                                                                                                                                                                                         |https://github.com/bharathichezhiyan/DravidianCodeMix-Dataset                   |DravidianCodeMix: sentiment analysis and offensive language identification dataset for Dravidian languages in code-mixed text|36                                                                                                                                |offensive |Youtube                                                                                                                       |Yes                                                         |60000      |Dravidian                                                                   |Dravidian -> Tamil                        |Not Offensive Offensive Untargeted Offensive Targeted Individual Offensive Targeted Group Offensive Targeted Other Not in indented language (: If the comment is not in the intended language)                                                                                                                                          |
|Arango et al. (2022)                                                                                                                                              |2022|Yes                                                                                                                                                                                         |https://github.com/aymeam/Datasets-for-Hate-Speech-Detection                    |Multilingual Resources for Offensive Language Detection|3                                                                                                                                 |offensive |Twitter                                                                                                                       |No                                                          |9834       |Spanish                                                                     |Indo-European -> Spanish                  |Some of the labels in the final dataset encompass different types of offensive content → hate speech, unintended profanity/vulgarity, insult/appellation, intentional profanity/vulgarity The other labels are not directly related to the offensive phenomenon, but help contextualize the messages and generalize the dataset.        |
|Bhattacharya et al. (2020)                                                                                                                                        |2022|Yes                                                                                                                                                                                         |https://sites.google.com/view/trac2/shared-task                                 |Developing a Multilingual Annotated Corpus of Misogyny and Aggression|66                                                                                                                                |aggressiveness, sexism/misogyny|Youtube                                                                                                                       |No                                                          |25000      |Bangla, Hindi                                                               |Indo-European -> Bangali, Indo-European -> Hindi|aggression (overtly aggressive, covertly aggressive, and non-aggressive) misogyny (gendered and non-gendered)                                                                                                                                                                                                                           |
|Kumar and Sachdeva (2022)                                                                                                                                         |2022|No                                                                                                                                                                                          |                                                                                |Multi-input integrative learning using deep neural networks and transfer learning for cyberbullying detection in real-time code-mix data|35                                                                                                                                |cyberbullying|Facebook, Twitter                                                                                                             |Yes                                                         |6500       |English, Hindi                                                              |Indo-European -> English, Indo-European -> Hindi|cyberbullying and non-bullying                                                                                                                                                                                                                                                                                                          |
|Amjad et al. (2021)                                                                                                                                               |2021|Yes                                                                                                                                                                                         |https://www.urduthreat2021.cicling.org/                                         |UrduThreat@ FIRE2021: Shared Track on Abusive Threat Identification in Urdu|20                                                                                                                                |abusive   |Twitter                                                                                                                       |No                                                          |8400       |Urdu                                                                        |Indo-European -> Urdu                     |Two dataset:  one →abusive/non abusive  another → Threatening and Non-Threatening                                                                                                                                                                                                                                                       |
|Mubarak et al. (2021)                                                                                                                                             |2021|Yes                                                                                                                                                                                         |https://competitions.codalab.org/competitions/22825                             |Arabic Offensive Language on Twitter: Analysis and Experiments|119                                                                                                                               |offensive |Twitter                                                                                                                       |No                                                          |10000      |Arabic                                                                      |Afro-Asiatic -> Arabic                    |Offensive / Clean  if Offensive → Vulgar/ Heat Speech                                                                                                                                                                                                                                                                                   |
|HASOC (2021)                                                                                                                                                      |2021|Yes                                                                                                                                                                                         |https://hasocfire.github.io/submission/leaderboard.html                         |Overview of the HASOC Subtrack at FIRE 2021: Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages and Conversational Hate Speech|94                                                                                                                                |hate speech, offensive|Twitter                                                                                                                       |No                                                          |13755      |English, Hindi, Marathi                                                     |Indo-European -> English, Indo-European -> Hindi, Indo-European -> Indo-Iranian -> Marathi|Task A : HOF - Hate and Offensive / NOT - Non Hate-Offensive  Task B → fine-grained classification for task A if HOF                HATE - Hate speech                OFFN - Offensive                PRFN - Profane                                                                                                                    |
|Pavlopoulos et al. (2021)                                                                                                                                         |2021|Yes                                                                                                                                                                                         |https://competitions.codalab.org/competitions/25623                             |SemEval-2021 Task 5: Toxic Spans Detection|92                                                                                                                                |toxic     |Civil Comments                                                                                                                |No                                                          |10629      |English                                                                     |Indo-European -> English                  |toxic or not if toxic →insult, threat, profanity                                                                                                                                                                                                                                                                                        |
|Burtenshaw and Kestemont (2021)                                                                                                                                   |2021|No                                                                                                                                                                                          |                                                                                |A Dutch Dataset for Cross-lingual Multilabel Toxicity Detection|2                                                                                                                                 |toxic     |Ask.fm                                                                                                                        |No                                                          |10189      |Dutch                                                                       |Indo-European -> Dutch                    |TOXICITY SEVERE_TOXICITY IDENTITY_ATTACK INSULT PROFANITY THREAT                                                                                                                                                                                                                                                                        |
|Adeep et al. (2021)                                                                                                                                               |2021|Yes                                                                                                                                                                                         |https://github.com/adeepH/Dravidian-OLI                                         |Offensive Language Identification in Low-resourced Code-mixed Dravidian languages using Pseudo-labeling|22                                                                                                                                |offensive |Youtube                                                                                                                       |Yes                                                         |71691      |Kannada, Malayalam, Tamil                                                   |Dravidian -> Kannada, Dravidian -> Malayalam, Dravidian -> Tamil|Not-Offensive (NO) Offensive-Targeted-Insult-Individual OTI): Offensive-Targeted-Insult-Group (OTG) Offensive-Targeted-Insult-Other (OTO) Offensive-Untargeted (OU) Others                                                                                                                                                              |
|HateXplain                                                                                                                                                        |2021|Yes                                                                                                                                                                                         |https://github.com/hate-alert/HateXplain                                        |HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection|269                                                                                                                               |hate speech|Gab, Twitter                                                                                                                  |No                                                          |20148      |English                                                                     |Indo-European -> English                  |hateful/offensive/normal                                                                                                                                                                                                                                                                                                                |
|Romim et al. (2021)                                                                                                                                               |2021|No                                                                                                                                                                                          |                                                                                |Hate Speech detection in the Bengali language: A dataset and its baseline evaluation|46                                                                                                                                |hate speech|Facebook, Youtube                                                                                                             |No                                                          |30000      |Bengali                                                                     |Indo-European -> Bangali                  |Sports  → (Hate speech /Not hate speech)  Entertainment → (Hate speech /Not hate speech)  Crime → (Hate speech /Not hate speech)  Religion → (Hate speech /Not hate speech)  Politics → (Hate speech /Not hate speech)  Celebrity → (Hate speech /Not hate speech)  Meme, TikTok and others → (Hate speech /Not hate speech)            |
|Vidgen et al. (2021)                                                                                                                                              |2021|Yes                                                                                                                                                                                         |https://github.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset            |Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection|92                                                                                                                                |hate speech|open-source platform                                                                                                          |No                                                          |41255      |English                                                                     |Indo-European -> English                  |Hate / Not Hate if Hate → Not given/Animosity/Dehumanization/Derogation/Support/Threatening                                                                                                                                                                                                                                             |
|Gaikwad et al. (2021)                                                                                                                                             |2021|Yes                                                                                                                                                                                         |https://github.com/tharindudr/MOLD                                              |Cross-lingual Offensive Language Identification for Low Resource Languages: The Case of Marathi|44                                                                                                                                |offensive |Twitter                                                                                                                       |No                                                          |2499       |Marathi                                                                     |Indo-European -> Indo-Iranian -> Marathi  |offensive (OFF)/ non-offensive (NOT) if OFF → targeted insult or thread                untargeted profanity Offensive language target identification: individual vs. group vs. other                                                                                                                                                    |
|Khan et al. (2021)                                                                                                                                                |2021|No                                                                                                                                                                                          |                                                                                |Hate Speech Detection in Roman Urdu|28                                                                                                                                |hate speech, offensive|Twitter                                                                                                                       |No                                                          |5000       |Roman Urdu                                                                  |Indo-European -> Roman Urdu               |Neutral/Hate Speech/Offensive                                                                                                                                                                                                                                                                                                           |
|Gaikwad et al. (2021) - MOLD                                                                                                                                      |2021|Yes                                                                                                                                                                                         |https://github.com/tharindudr/MOLD                                              |          |39                                                                                                                                |offensive |Twitter                                                                                                                       |No                                                          |2500       |Marathi                                                                     |Indo-European -> Indo-Iranian -> Marathi  |Level A: Offensive language identification: offensive (OFF) vs. non-offensive (NOT)  Level B: Categorization of offensive language: targeted insult or thread vs. untargeted profanity.  Level C: Offensive language target identification: individual vs. group vs. other.                                                             |
|Kaggle Jigsaw Multilingual Toxic Comment                                                                                                                          |2020|Yes                                                                                                                                                                                         |https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification       |          |                                                                                                                                  |toxic     |Civil Comments, Wikipedia                                                                                                     |No                                                          |2171829    |English, Portuguese, Spanish, Turkish                                       |Indo-European -> English, Indo-European -> Portuguese, Indo-European -> Spanish, Turkic -> Turkish|toxic comment • toxic • severe_toxic • obscene • threat • insult • identity_hate  unintened bias • severe_toxicity • obscene • threat • insult • identity_attack • sexual_explicit                                                                                                                                                      |
|HaSpeeDe 2 Evalita (2020)                                                                                                                                         |2020|Yes                                                                                                                                                                                         |https://live.european-language-grid.eu/catalogue/corpus/7498                    |HaSpeeDe 2 @ EVALITA2020: Overview of the EVALITA 2020 Hate Speech Detection Task|56                                                                                                                                |hate speech|Twitter                                                                                                                       |No                                                          |12081      |Italian                                                                     |Indo-European -> Italian                  |Hate Speech (binary) Stereotype (binary) Nominal Utterances (binary)                                                                                                                                                                                                                                                                    |
|Kumar et al (2020) - TRAC-2                                                                                                                                       |2020|Yes                                                                                                                                                                                         |https://sites.google.com/view/trac2/shared-task                                 |https://aclanthology.org/2020.trac-1.1.pdf|109                                                                                                                               |aggressiveness|Youtube                                                                                                                       |No                                                          |15000      |Bengali, English, Hindi                                                     |Indo-European -> Bangali, Indo-European -> English, Indo-European -> Hindi|Task A Overtly Aggressive (OAG) Covertly Aggressive (CAG) Non-Aggressive (NAG) Task B gendered (GEN) non-gendered (NGEN)                                                                                                                                                                                                                |
|HASOC (2020)                                                                                                                                                      |2020|Yes                                                                                                                                                                                         |https://hasocfire.github.io/hasoc/2020/dataset.html                             |Overview of the HASOC Track at FIRE 2020: Hate Speech and Offensive Language Identification in Tamil, Malayalam, Hindi, English and German|122                                                                                                                               |offensive |Twitter, Youtube                                                                                                              |Yes                                                         |15047      |English, German, Hindi, Malayalam, Tamil                                    |Dravidian -> Malayalam, Dravidian -> Tamil, Indo-European -> English, Indo-European -> Hindi, Indo-European->Germanic|NOT: Non Hate-Offensive HOF: Hate and Offensive if HOF → HATE: Hate speech/ OFFN: Offensive/PRFN: Profane                                                                                                                                                                                                                               |
|OffensEval (2020) - SOLID                                                                                                                                         |2020|Yes                                                                                                                                                                                         |https://sites.google.com/site/offensevalsharedtask/home                         |https://aclanthology.org/2020.semeval-1.188.pdf|399                                                                                                                               |offensive |Twitter                                                                                                                       |No                                                          |9000000    |Arabic, Danish, English, Greek, Turkish                                     |Afro-Asiatic -> Arabic, Indo-European -> Danish, Indo-European -> English, Indo-European -> Greek, Turkic -> Turkish|A: Offensive Language Detection(offensive/ not offensive) B: Categorization of Offensive Language (Is the offensive text targeted (TIN) or untargeted (UNT)) C: Offensive Language Target Identification(individual/group/other)                                                                                                        |
|Pitenis et al. (2020) - OGTD                                                                                                                                      |2020|Yes                                                                                                                                                                                         |https://github.com/tharindudr/aggression-detection-greek                        |Offensive Language Identification in Greek|126                                                                                                                               |offensive |Twitter                                                                                                                       |No                                                          |4779       |Greek                                                                       |Indo-European -> Greek                    |offensive (binary)                                                                                                                                                                                                                                                                                                                      |
|Charitidis et al. (2020)                                                                                                                                          |2020|Yes                                                                                                                                                                                         |https://zenodo.org/record/3520152#.XcL0OnUzY5k https://zenodo.org/record/3520156#.XcL04XUzY5k  https://zenodo.org/record/3520148#.XcL04XUzY5k  https://zenodo.org/record/3520150#.XcL1C3UzY5k  https://zenodo.org/record/3520157#.XcL1G3UzY5k|Towards countering hate speech against journalists on social media|40                                                                                                                                |hate speech|Twitter                                                                                                                       |No                                                          |264035     |English, French, German, Greek, Spanish                                     |Indo-European -> English, Indo-European -> Greek, Indo-European -> Italic -> French, Indo-European -> Spanish, Indo-European->Germanic|Hate Positive /Negative                                                                                                                                                                                                                                                                                                                 |
|XHATE-999                                                                                                                                                         |2020|Yes                                                                                                                                                                                         |https://github.com/codogogo/xhate                                               |https://aclanthology.org/2020.coling-main.559.pdf|49                                                                                                                                |abusive, hate speech|Facebook, Fox news, Twitter, Wikipedia                                                                                        |No                                                          |109955     |Albanian, Croatian, English, German, Russian, Turkish                       |Indo-European -> Albanian, Indo-European -> Croatian, Indo-European -> English, Indo-European -> Russian, Indo-European->Germanic, Turkic -> Turkish|abusive vs. non-abusive                                                                                                                                                                                                                                                                                                                 |
|Shekhar et al. (2020)                                                                                                                                             |2020|No                                                                                                                                                                                          |                                                                                |Automating News Comment Moderation with Limited Resources: Benchmarking in Croatian and Estonian|12                                                                                                                                |offensive |24sata, Eesti Ekspress, Veˇcernji List                                                                                        |No                                                          |62600000   |Croatian, Estonian                                                          |Indo-European -> Croatian, Uralic -> Estonian|Disallowed content, Threats, Hate speech, Obscenity, Deception & trolling, Vulgarity, Language, Abuse                                                                                                                                                                                                                                   |
|Akhter et al. (2020)                                                                                                                                              |2020|Yes                                                                                                                                                                                         |https://github.com/pervezbcs/Urdu-Abusive-Dataset                               |Automatic Detection of Offensive Language for Urdu and Roman Urdu|52                                                                                                                                |abusive, offensive|Youtube                                                                                                                       |No                                                          |12171      |Roman Urdu, Urdu                                                            |Indo-European -> Urdu                     |Binary  offensive /non offensive                                                                                                                                                                                                                                                                                                        |
|Kaggle Korean Hate Speech Dataset                                                                                                                                 |2020|Yes                                                                                                                                                                                         |https://www.kaggle.com/datasets/captainnemo9292/korean-hate-speech-dataset      |          |                                                                                                                                  |hate speech|alt-right website                                                                                                             |No                                                          |189995     |Korean                                                                      |Koreanic -> Korean                        |0 for hate speech, 1 for normal                                                                                                                                                                                                                                                                                                         |
|Rizwan et al. (2020)                                                                                                                                              |2020|Yes                                                                                                                                                                                         |https://paperswithcode.com/dataset/rushold                                      |Hate speech and offensive language detection in Roman Urdu|45                                                                                                                                |hate speech, offensive|Twitter                                                                                                                       |No                                                          |10012      |Roman Urdu                                                                  |Indo-European -> Roman Urdu               |1) Abusive/Offensive 2)Profane 3) Sexism 4) Religious 5) Neutral                                                                                                                                                                                                                                                                        |
|Kennedy et al. (2020)                                                                                                                                             |2020|Yes                                                                                                                                                                                         |https://github.com/BrendanKennedy/contextualizing-hate-speech-models-with-explanations|Contextualizing Hate Speech Classifiers with Post-hoc Explanation|118                                                                                                                               |hate speech|Gab                                                                                                                           |No                                                          |27655      |English                                                                     |Indo-European -> English                  |Hate (binary)                                                                                                                                                                                                                                                                                                                           |
|Çöltekin (2020)                                                                                                                                                   |2020|Yes                                                                                                                                                                                         |https://coltekin.github.io/offensive-turkish/                                   |A Corpus of Turkish Offensive Language on Social Media|125                                                                                                                               |offensive |Twitter                                                                                                                       |No                                                          |36232      |Turkish                                                                     |Turkic -> Turkish                         |offensive/Not offensive  if offensive → Non target/target                        if target → group/ individual /other                                                                                                                                                                                                                   |
|Sigurbergsson and Derczynski (2020)                                                                                                                               |2020|Yes                                                                                                                                                                                         |https://paperswithcode.com/dataset/dkhate                                       |Offensive Language and Hate Speech Detection for Danish|145                                                                                                                               |abusive, offensive|Facebook, Reddit, Twitter                                                                                                     |No                                                          |3600       |Danish                                                                      |Indo-European -> Danish                   |Offensive language → NOT OFF If OFF→ Automatic categorization of offensive language types→Targeted Insult (TIN) /Untargeted (UNT) if TIN → Individual group or other                                                                                                                                                                    |
|Adeep et al. (2020)?                                                                                                                                              |2020|No                                                                                                                                                                                          |                                                                                |KanCMD: Kannada CodeMixed Dataset for Sentiment Analysis and Offensive Language Detection|95                                                                                                                                |offensive |Youtube                                                                                                                       |Yes                                                         |7671       |Kannada                                                                     |Dravidian -> Tamil                        |Sentiment Analysis: Positive state/ Negative state/ Mixed feelings/ Neutral state/ Not in intended language  Offensive Language Identification: Not Offensive/Offensive Untargeted/Offensive Targeted Individual/Offensive Targeted Group/ Offensive Targeted Other/  Not in intended language                                          |
|Kaggle Russian Language Toxic Comments Dataset                                                                                                                    |2019|Yes                                                                                                                                                                                         |https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments       |Kaggle Russian Language Toxic Comments Dataset|                                                                                                                                  |toxic     |2ch                                                                                                                           |No                                                          |14412      |Russian                                                                     |Indo-European -> Russian                  |toxic or non-toxic                                                                                                                                                                                                                                                                                                                      |
|GermEval (2019)                                                                                                                                                   |2019|Yes                                                                                                                                                                                         |https://fz.h-da.de/iggsa/data                                                   |Overview of GermEval Task 2, 2019 shared task on the identification of offensive language|100                                                                                                                               |offensive |Twitter                                                                                                                       |No                                                          |7025       |German                                                                      |Indo-European->Germanic                   |OTHER OFFENSE → ABUSE/INSULT/PROFANITY/OTHER                                                                                                                                                                                                                                                                                            |
|OffensEval (2019) - OLID                                                                                                                                          |2019|Yes                                                                                                                                                                                         |https://aclanthology.org/N19-1144/                                              |SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval) / Predicting the Type and Target of Offensive Posts in Social Media|664                                                                                                                               |offensive |Twitter                                                                                                                       |No                                                          |14000      |English                                                                     |Indo-European -> English                  |a: Offensive Language Detection (binary) b: Categorization of Offensive Language (Targeted Insult/untargeted) c: Offensive Language Target Identification (individual/group)                                                                                                                                                            |
|PolEval (2019)                                                                                                                                                    |2019|Yes                                                                                                                                                                                         |https://github.com/ptaszynski/cyberbullying-Polish                              |Results of the PolEval 2019 Shared Task 6 : first dataset and Open Shared Task for automatic cyberbullying detection in Polish Twitter|13                                                                                                                                |cyberbullying, toxic|Twitter                                                                                                                       |No                                                          |11041      |Polish                                                                      |Indo-European -> Polish                   |Not harmful harmful → cyberbullying                    hate-speech                   other harmful                                                                                                                                                                                                                                      |
|HASOC (2019)                                                                                                                                                      |2019|Yes                                                                                                                                                                                         |https://hasocfire.github.io/hasoc/2019/dataset.html                             |Overview of the HASOC track at FIRE 2019: Hate Speech and Offensive Content Identification in Indo-European Languages|69                                                                                                                                |hate speech, offensive|Facebook, Twitter                                                                                                             |No                                                          |17657      |English, German, Hindi                                                      |Indo-European -> English, Indo-European -> Hindi, Indo-European->Germanic|1. SUB-TASK A: classification of Hate Speech (HOF) and non-offensive content. → (NOT) Non Hate-Offensive/(HOF) Hate and Offensive 2. SUB-TASK B: If the post is HOF, sub-task B is used to identify the type of hate.→ (HATE) Hate speech/(OFFN) Offensive/(PRFN) Profane 3. SUB-TASK C: it decides the target of the post.→ Targeted Insult (TIN)/Untargeted (UNT)|
|HatEval (2019)                                                                                                                                                    |2019|Yes                                                                                                                                                                                         |http://hatespeech.di.unito.it/hateval.html                                      |          |723                                                                                                                               |aggressiveness, hate speech|Twitter                                                                                                                       |No                                                          |19600      |English, Spanish                                                            |Indo-European -> English, Indo-European -> Spanish|Hate speech (binary);  Target Range(TR) - generic or individual;  Aggressiveness (binary)                                                                                                                                                                                                                                               |
|FRENK (2021)                                                                                                                                                      |2019|No                                                                                                                                                                                          |                                                                                |The FRENK Datasets of Socially Unacceptable Discourse in Slovene and English|33                                                                                                                                |offensive |Facebook                                                                                                                      |Yes                                                         |22877      |English, Slovene                                                            |Indo-European -> English, Indo-European -> Slovene|Is this SUD aimed at someone’s background?          YES: Are there elements of violence?                    YES: background, violence                    NO: background, offensive speech          NO: Is this SUD aimed towards individuals or other groups?                 YES: Are there elements of violence?                         YES: other, threat                         NO: other, offensive speech                 NO: Is the speech unacceptable?                        YES: inappropriate speech                         NO: acceptable speech  Acceptable  Background, violence  Background, offensive  Other, offensive  Other, offensive |
|Arata (2019)                                                                                                                                                      |2019|No                                                                                                                                                                                          |                                                                                |Study on change of detection accuracy over time in cyberbullying detection|                                                                                                                                  |cyberbullying|Twitter                                                                                                                       |No                                                          |4096       |Japanese                                                                    |Japonic -> Japanese                       |1,0                                                                                                                                                                                                                                                                                                                                     |
|Arango et al. (2019)                                                                                                                                              |2019|Yes                                                                                                                                                                                         |https://github.com/aymeam/User_distribution_experiments                         |Hate Speech Detection is Not as Easy as You May Think: A Closer Look at Model Validation|170                                                                                                                               |hate speech|Twitter                                                                                                                       |No                                                          |14949      |English                                                                     |Indo-European -> English                  |                                                                                                                                                                                                                                                                                                                                        |
|Ibrohim and Budi (2019)                                                                                                                                           |2019|Yes                                                                                                                                                                                         |https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection|Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter|167                                                                                                                               |abusive, hate speech|Twitter                                                                                                                       |No                                                          |5561       |Indonesian                                                                  |Austronesian -> Indonesian                |• HS : hate speech label; • Abusive : abusive language label; • HS_Individual : hate speech targeted to an individual; • HS_Group : hate speech targeted to a group; • HS_Religion : hate speech related to religion/creed; • HS_Race : hate speech related to race/ethnicity; • HS_Physical : hate speech related to physical/disability; • HS_Gender : hate speech related to gender/sexual orientation; • HS_Gender : hate related to other invective/slander; • HS_Weak : weak hate speech; • HS_Moderate : moderate hate speech; • HS_Strong : strong hate speech.|
|Mulki et al. (2019)                                                                                                                                               |2019|No                                                                                                                                                                                          |                                                                                |https://aclanthology.org/W19-3512.pdf|118                                                                                                                               |abusive, hate speech, toxic|Twitter                                                                                                                       |No                                                          |5846       |Arabic                                                                      |Afro-Asiatic -> Arabic                    |Normal/Abusive/Hate                                                                                                                                                                                                                                                                                                                     |
|Pereira-Kohatsu et al. (2019)                                                                                                                                     |2019|Yes                                                                                                                                                                                         |https://zenodo.org/record/2592149                                               |Detecting and Monitoring Hate Speech in Twitter|79                                                                                                                                |hate speech|Twitter                                                                                                                       |No                                                          |6000       |Spanish                                                                     |Indo-European -> Spanish                  |                                                                                                                                                                                                                                                                                                                                        |
|Fortuna et al. (2019)                                                                                                                                             |2019|Yes                                                                                                                                                                                         |https://github.com/paulafortuna/SemEval_2019_public                             |A Hierarchically-Labeled Portuguese Hate Speech Dataset|80                                                                                                                                |hate speech, offensive|Twitter                                                                                                                       |No                                                          |5668       |Portuguese                                                                  |Indo-European -> Portuguese               |Hate/Non Hate → non expert if Hate → then expert annotated with 81 hate categories                                                                                                                                                                                                                                                      |
|Chung et al. (2019) - CONAN                                                                                                                                       |2019|Yes                                                                                                                                                                                         |https://github.com/marcoguerini/CONAN                                           |CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech|136                                                                                                                               |hate speech|Twitter                                                                                                                       |No                                                          |4078       |English, French, Italian                                                    |Indo-European -> English, Indo-European -> Italian, Indo-European -> Italic -> French|CULTURE, criticizing Islamic culture or particular aspects such as religious events or clothes; ECONOMICS, hate statements about Muslims taking European workplaces or not contributing economically to the society;  CRIMES, hate statements about Muslims committing actions against the law; RAPISM, a very frequent topic in hate speech, for this reason it has been isolated from the previous category;  TERRORISM, accusing Muslims of being terrorists, killers, preparing attacks;  WOMEN OPPRESSION, criticizing Muslims for their behavior against women; HISTORY, stating that we should hate Muslims because of historical events; OTHER/GENERIC, everything that does not fall|
|Ousidhoum et al. (2019)                                                                                                                                           |2019|Yes                                                                                                                                                                                         |https://github.com/HKUST-KnowComp/MLMA_hate_speech                              |          |190                                                                                                                               |hate speech|Twitter                                                                                                                       |No                                                          |13014      |Arabic, English, French                                                     |Afro-Asiatic -> Arabic, Indo-European -> English, Indo-European -> Italic -> French|1. Directness (binary) 2. Hostility       a. Abusive      b. hateful       c. Disrespectful      d. fearful       e. normal 3. Target     a. Origin     b. gender     c. sex orient     d. religion      e. disability     f. other 4. Group     a . Individual     b. other     c. women      d. specNeeds     e. African   5.annotator     a. Disgust      b. shock      c. anger     d. sadness     e. fear     f. confusion      g. Indifference |
|Chiril et al. (2019)                                                                                                                                              |2019|No                                                                                                                                                                                          |                                                                                |          |22                                                                                                                                |sexism/misogyny|Twitter                                                                                                                       |No                                                          |3085       |French                                                                      |Indo-European -> Italic -> French         |sexist or non sexist                                                                                                                                                                                                                                                                                                                    |
|Mathur et al. (2018) - HOT                                                                                                                                        |2018|Yes                                                                                                                                                                                         |www.github.com/pmathur5k10/ Hinglish-Offensive-Text-Classification              |Did you offend me? Classification of Offensive Tweets in Hinglish Language|95                                                                                                                                |abusive, hate speech, offensive|Twitter                                                                                                                       |No                                                          |17698      |English, Hindi                                                              |Indo-European -> English, Indo-European -> Hindi|Non-offensive Abusive Hate-inducing                                                                                                                                                                                                                                                                                                     |
|Kumar et al. (2018) - TRAC-1                                                                                                                                      |2018|Yes                                                                                                                                                                                         |https://sites.google.com/view/trac1/shared-task?authuser=0                      |https://aclanthology.org/L18-1226.pdf|149                                                                                                                               |aggressiveness|Facebook, Twitter                                                                                                             |Yes                                                         |39000      |English, Hindi                                                              |Indo-European -> English, Indo-European -> Hindi|1:Overtly Aggressive  2:Covertly Aggressive 3:Non Aggressive For 1 and 2: Discursive Role → attack/defend/Abet Discursive effect → Physical Threat, Sexual Aggression, Gendered Aggression, Racial Aggression, Communal Aggression, Casteist Aggression, Political Aggression, Geographical Aggression, General Non-threatening Aggression, Curse / abuse   |
|GermEval (2018)                                                                                                                                                   |2018|Yes                                                                                                                                                                                         |https://projects.cai.fbi.h-da.de/iggsa/                                         |          |287                                                                                                                               |hate speech, offensive|Twitter                                                                                                                       |No                                                          |8541       |German                                                                      |Indo-European->Germanic                   |offensive (binary) ABUSE INSULT PROFANITY OTHER other                                                                                                                                                                                                                                                                                   |
|HaSpeeDe Evalita (2018)                                                                                                                                           |2018|Yes                                                                                                                                                                                         |http://www.di.unito.it/~tutreeb/haspeede-evalita18/                             |          |173                                                                                                                               |hate speech|Facebook, Twitter                                                                                                             |No                                                          |4000       |Italian                                                                     |Indo-European -> English, Indo-European -> Italian|Hate speech (binary)                                                                                                                                                                                                                                                                                                                    |
|AMI IberEval                                                                                                                                                      |2018|Yes                                                                                                                                                                                         |https://sites.google.com/view/ibereval-2018                                     |Overview of the Task on Automatic Misogyny Identification at IberEval 2018|214                                                                                                                               |sexism/misogyny|Twitter                                                                                                                       |No                                                          |8115       |English, Spanish                                                            |Indo-European -> English, Indo-European -> Spanish|misogynous (binary) if misogynous →                       stereotype: denotes the category Stereotype & Objectification;                       dominance: denotes the category Dominance;                       derailing: denotes the category Derailing;                       sexual harassment: denotes the category Sexual Harassment & Threats of Violence;                       discredit: denotes the category Discredit      active: individual;    passive: generic|
|AMI Evalita (2018)                                                                                                                                                |2018|Yes                                                                                                                                                                                         |https://amievalita2018.wordpress.com/data/                                      |          |162                                                                                                                               |sexism/misogyny|Twitter                                                                                                                       |No                                                          |20000      |English, Italian                                                            |Indo-European -> English, Indo-European -> Italian|• Misogyny ( binary) • Misogynistic Category (Discredit, Derailing, Dominance, Sexual Harassment & Threats of Violence, Stereotype & Objectification) • Target (Active vs Passive)                                                                                                                                                      |
|Gibert et al. (2018)                                                                                                                                              |2018|Yes                                                                                                                                                                                         |https://github.com/Vicomtech/hate-speech-dataset                                |https://aclanthology.org/W18-5102.pdf|345                                                                                                                               |hate speech|Stormfront                                                                                                                    |No                                                          |10568      |English                                                                     |Indo-European -> English                  |Hate No hate  Skip → Sentences that are not written in English or that do not contain information as to be classified into HATE or NOHATE are given this label                                                                                                                                                                          |
|Ptaszynski et al. (2018)                                                                                                                                          |2018|No                                                                                                                                                                                          |                                                                                |Cyberbullying Detection -- Technical Report 2/2018, Department of Computer Science AGH, University of Science and Technology|19                                                                                                                                |cyberbullying|Formspring.me                                                                                                                 |No                                                          |12772      |English                                                                     |Indo-European -> English                  |0 – text certainly does not contain online violence; 1 – text certainly contains online violence; 2 – uncertain case                                                                                                                                                                                                                    |
|Alakrot et al. (2018)                                                                                                                                             |2018|Yes                                                                                                                                                                                         |https://onedrive.live.com/?authkey=%21ACDXj%5FZNcZPqzy0&id=6EF6951FBF8217F9%21105&cid=6EF6951FBF8217F9|Dataset Construction for the Detection of Anti-Social Behaviour in Online Communication in Arabic|66                                                                                                                                |abusive, offensive|Youtube                                                                                                                       |No                                                          |167549     |Arabic                                                                      |Afro-Asiatic -> Arabic                    |offensive as positive  inoffensive as negative                                                                                                                                                                                                                                                                                          |
|Bohra et al. (2018)                                                                                                                                               |2018|Yes                                                                                                                                                                                         |https://github.com/deepanshu1995/HateSpeech-Hindi-English-Code-Mixed-Social-Media-Text|https://aclanthology.org/W18-1105.pdf|207                                                                                                                               |hate speech|Twitter                                                                                                                       |Yes                                                         |4575       |English, Hindi                                                              |Indo-European -> English, Indo-European -> Hindi|Hate Speech Normal Speech                                                                                                                                                                                                                                                                                                               |
|ElSherief et al. (2018)                                                                                                                                           |2018|Yes                                                                                                                                                                                         |https://github.com/melsherief/hate_speech_icwsm18                               |Peer to Peer Hate: Hate Speech Instigators and Their Targets|165                                                                                                                               |hate speech|Twitter                                                                                                                       |No                                                          |27330      |English                                                                     |Indo-European -> English                  |Class, Sexual Orientation , Disability, Gender, Ethnicity), Nationality, Religion, Archaic                                                                                                                                                                                                                                              |
|Mathur et al (2018) - HEOT                                                                                                                                        |2018|No                                                                                                                                                                                          |                                                                                |          |147                                                                                                                               |offensive |Twitter                                                                                                                       |Yes                                                         |3679       |English, Hindi                                                              |Indo-European -> English, Indo-European -> Hindi|non-offensive, abusive and hate-speech                                                                                                                                                                                                                                                                                                  |
|Sanguinetti et al. (2018)                                                                                                                                         |2018|Yes                                                                                                                                                                                         |https://github.com/msang/hate-speech-corpus                                     |An Italian Twitter Corpus of Hate Speech against Immigrants|192                                                                                                                               |aggressiveness, hate speech, offensive|Twitter                                                                                                                       |No                                                          |6000       |Italian                                                                     |Indo-European -> Italian                  |hate speech: no - yes   —> intensity: 0 - 1 - 2 - 3 - 4 aggressiveness: no - weak - strong offensiveness: no - weak - strong irony: no - yes stereotype: no - yes                                                                                                                                                                       |
|Founta et al. (2018)                                                                                                                                              |2018|Yes                                                                                                                                                                                         |https://github.com/ENCASEH2020/hatespeech-twitter                               |Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior|540                                                                                                                               |abusive, hate speech|Twitter                                                                                                                       |No                                                          |80000      |English                                                                     |Indo-European -> English                  |Abusive, Hateful, Normal, Spam                                                                                                                                                                                                                                                                                                          |
|Golbeck et al. (2017)                                                                                                                                             |2017|Yes                                                                                                                                                                                         |                                                                                |          |57                                                                                                                                |harassment, offensive, racism, sexism/misogyny|Block Together, Twitter                                                                                                       |No                                                          |35000      |English                                                                     |Indo-European -> English                  |H - harassing, N - non-harassing                                                                                                                                                                                                                                                                                                        |
|Devyatkin et al. (2017)                                                                                                                                           |2017|No                                                                                                                                                                                          |                                                                                |Exploring linguistic features for extremist texts detection (on the material of Russian-speaking illegal texts)|27                                                                                                                                |offensive |Twitter                                                                                                                       |No                                                          |493        |Russian                                                                     |Indo-European -> Russian                  |terrorism, ideological texts, religious hatred, separatism, nationalism, aggression, calls for insurgency, fascism                                                                                                                                                                                                                      |
|Gao and Huang (2017)                                                                                                                                              |2017|Yes                                                                                                                                                                                         |https://github.com/sjtuprog/fox-news-comments                                   |https://doi.org/10.26615/978-954-452-049-6_036|220                                                                                                                               |hate speech|Fox news                                                                                                                      |No                                                          |1528       |English                                                                     |Indo-European -> English                  |Hateful speech (yes or no)                                                                                                                                                                                                                                                                                                              |
|Wulczyn et al (2017)                                                                                                                                              |2017|Yes                                                                                                                                                                                         |https://github.com/ewulczyn/wiki-detox/tree/master/src/data_generation          |Ex Machina: Personal Attacks Seen at Scale|743                                                                                                                               |offensive |Wikipedia                                                                                                                     |No                                                          |115737     |English                                                                     |Indo-European -> English                  |empirical distribution (ED) one-hot (OH)                                                                                                                                                                                                                                                                                                |
|Pelle and Moreira (2017)                                                                                                                                          |2017|Yes                                                                                                                                                                                         |http://inf.ufrgs.br/ ̃rppelle/hatedetector                                      |Offensive comments in the Brazilian Web: a dataset and baseline results|77                                                                                                                                |hate speech, offensive|g1.globo.com                                                                                                                  |No                                                          |1250       |Portuguese                                                                  |Indo-European -> Portuguese               |offensive (yes/no) if yes → racism, sexism, homophobia, xenophobia, religious in-tolerance, or cursing                                                                                                                                                                                                                                  |
|Ross et al. (2017)                                                                                                                                                |2017|Yes                                                                                                                                                                                         |https://github.com/UCSM-DUE/                                                    |Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis|430                                                                                                                               |hate speech, offensive|Twitter                                                                                                                       |No                                                          |541        |German                                                                      |Indo-European->Germanic                   |Hate Speech (yes/no) Should it be banned from tweet (yes/no) How offensive 0 to 6 → anything 4 or higher it is offensive                                                                                                                                                                                                                |
|Alfina et al. (2017)                                                                                                                                              |2017|Yes                                                                                                                                                                                         |https://github.com/ialfina/id-hatespeech-detection                              |Hate speech detection in the Indonesian language: A dataset and preliminary study|177                                                                                                                               |hate speech|Twitter                                                                                                                       |No                                                          |713        |Indonesian                                                                  |Austronesian -> Indonesian                |Hate speech / Not Hate Speech                                                                                                                                                                                                                                                                                                           |
|Fortuna (2017)                                                                                                                                                    |2017|Yes                                                                                                                                                                                         |https://rdm.inesctec.pt/id/dataset/cs-2017-008#                                 |Automatic detection of hate speech in text: an overview of the topic and dataset annotation with hierarchical classes|49                                                                                                                                |hate speech|Twitter                                                                                                                       |No                                                          |5668       |Portuguese                                                                  |Indo-European -> Portuguese               |Hate Speech /none  If Hate → “Health”, “Homo-phobia”, “Ideology”, “Origin”, “Racism”, “Religion”, “Sexism” and “Other-lifestyle”                                                                                                                                                                                                        |
|Bretschneider and Peters (2017)                                                                                                                                   |2017|Yes                                                                                                                                                                                         |http://www.ub-web.de/research/                                                  |Detecting Offensive Statements towards Foreigners in Social Media|50                                                                                                                                |hate speech, offensive|Facebook                                                                                                                      |No                                                          |5836       |German                                                                      |Indo-European->Germanic                   |• the field "valence" represents the perceived severity     ◦ valence = 1: moderately offending     ◦ valence = 2: clearly to substantially offending • The field "target type" represents the target class     ◦ target_type = 1: no target at all     ◦ target_type = 2: foreigner or refugee     ◦ target_type = 3: politicians or government     ◦ target_type = 5: other target     ◦ target_type = 6: unknown target     ◦ target_type = 7: community of the Facebook page     ◦ target_type = 8: press|
|Davidson et al. (2017)                                                                                                                                            |2017|Yes                                                                                                                                                                                         |https://github.com/t-davidson/hate-speech-and-offensive-language                |          |2191                                                                                                                              |offensive |Twitter                                                                                                                       |No                                                          |24802      |English                                                                     |Indo-European -> English                  |hate speech, offensive but not hate speech, or neither offensive nor hate speech                                                                                                                                                                                                                                                        |
|Mubarak et al. (2017)                                                                                                                                             |2017|Yes                                                                                                                                                                                         |https://github.com/nuhaalbadi/Arabic_hatespeech                                 |https://aclanthology.org/W17-3008.pdf|265                                                                                                                               |abusive, hate speech, offensive|Twitter                                                                                                                       |No                                                          |32000      |Arabic                                                                      |Afro-Asiatic -> Arabic                    |obscene offensive clean                                                                                                                                                                                                                                                                                                                 |
|Waseem and Hovy (2016)                                                                                                                                            |2016|Yes                                                                                                                                                                                         |https://github.com/zeeraktalat/hatespeech                                       |https://aclanthology.org/N16-2013.pdf|1541                                                                                                                              |hate speech|Twitter                                                                                                                       |No                                                          |16914      |English                                                                     |Indo-European -> English                  |offensive                                                                                                                                                                                                                                                                                                                               |
|AMiCA                                                                                                                                                             |2015|No                                                                                                                                                                                          |                                                                                |Automatic detection and prevention of cyberbullying|100                                                                                                                               |cyberbullying|Ask.fm                                                                                                                        |No                                                          |85462      |Dutch                                                                       |Indo-European -> Dutch                    |harmfulness 0 → the post does not contain indications of cyberbullying.                      1 → the post contains indications of cyberbullying but not severe,                       2 →  serious indications of cyberbullying if 1 or 2 then              Threat/blackmail             Insult             Curse/exclusion             Defamation             Sexual talk             Defense             Encouragements to the harasser|
|Ptaszynski et al. (2010)                                                                                                                                          |2010|No                                                                                                                                                                                          |                                                                                |Machine Learning and Affect Analysis Against Cyber-Bullying|56                                                                                                                                |cyberbullying|informal web sites of Japanese secondary schools                                                                              |No                                                          |2999       |Japanese                                                                    |Japonic -> Japanese                       |valence (polarity) of emotions          positive emotion → harmful/non harmful           negative/positive emotion → harmful/non harmful           negative emotion → harmful/non harmful  activation of emotions          deactivated emotion → harmful/non harmful           moderately activated emotion→ harmful/non harmful           activated emotion→ harmful/non harmful    |
